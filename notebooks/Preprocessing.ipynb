{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Exploration des forms et des mots"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Définition des constantes"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
     "import pandas as pd\n",
     "import seaborn as sns\n",
     "import matplotlib.pyplot as plt\n",
     "import matplotlib.patches as patches\n",
     "import numpy as np\n",
     "from lxml import etree  # pour la fonction get_words_from_xml_form()\n",
     "import glob  # pour la fonction get_files()\n",
     "from collections import Counter\n",
     "import cv2\n",
     "\n",
     "import ressources as rss\n",
     "import preprocessing as pp\n",
     "import dataviz as dv\n",
     "import rendering as rd"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# UNIQUEMENT UTILE pour recharger les librairies plus rapidement lors des devs\n",
     "import importlib\n",
     "importlib.reload(rss)\n",
     "importlib.reload(pp)\n",
     "importlib.reload(dv)\n",
     "importlib.reload(rd)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# initialisation des variables globales\n",
     "rss.init()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Preprocessing"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Lecture des données des forms dans un dataframe : form_df"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "scrolled": true
    },
    "outputs": [],
    "source": [
     "form_df = pd.DataFrame(pp.parse_my_form_file(rss.FORMS_META_FILENAME), columns=rss.FORMS_COLUMNS)\n",
     "#form_df.head()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "%%capture \n",
     "\n",
     "form_df = pp.prepro_form(form_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "print('Le dataset des forms dispose de ' + str(form_df.shape[0]) +' entrées.')"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# %%time\n",
     "\n",
     "pp.check_all_forms_images(form_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Lecture des données des mots dans un DF : word_df"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "word_df = pd.DataFrame(pp.parse_my_word_file(rss.WORDS_META_FILENAME), columns=rss.WORD_COLUMNS)\n",
     "word_df.head()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "%%capture  #no_output\n",
     "\n",
     "word_df = pp.prepro_word(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "print('Le dataset des mots dispose de ' + str(word_df.shape[0]) +' entrées.')"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Deux fichiers de mots sont corrompus [4152, 113621]. Ils sont supprimés du dataframe. Les mots mal segmentés sont également supprimés."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Le dataset dispose de 115318 mots scannés, dont 96420 mots avec segmentation OK, qui constitueront notre base finale."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Création du dataframe mergé\n",
     "df_all = pp.prepro_all(word_df, form_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Outils de rendering"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Affichage des forms et des mots"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# rd.show_word_image_by_line(word_df.iloc[0])"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# rd.show_form_img_by_word_id(form_df.iloc[0])"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Affichage des contours sur les forms"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "indice = np.random.randint(0, word_df.shape[0])\n",
     "\n",
     "\n",
     "rd.plot_bounding_box_with_form(indice, word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Analyse des Forms"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Représentation globale des forms"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "rd.show_10_forms(form_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse du volume de lignes et mots par form"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "\n",
     "dv.show_lines_word_per_form(form_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse de la distribution de rédacteurs et de textes"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "nb_textes = len(form_df.text_id.unique())\n",
     "nb_auteurs = len(form_df.writer_id.unique())\n",
     "\n",
     "print('Le dataset de forms est constitué de '+str(nb_textes)+' textes uniques rédigés par '+str(nb_auteurs)+' rédacteurs.')\n",
     "      "
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "count_per_writer_df = form_df[['writer_id', 'form_id']].groupby(\"writer_id\").count()\n",
     "count_per_writer_df.columns = ['nb_forms']\n",
     "print(count_per_writer_df.describe())\n",
     "dv.show_count_per_wirter(count_per_writer_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "On remarque une moyenne de 2,34 forms par rédacteur et un écart moyen de l'ordre de 3 avec un minimum de 1 et un maximum de 59: Il semble donc y avoir un/des outliers."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Le rédacteur ayant l'identifiant 000 a un volume beaucoup plus important que tous les autres rédacteurs.\n",
     "Hypothèse à tester : l'indice 000 indique un rédacteur inconnu."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "rd.show_6forms_from_writer000(form_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "L'hypothèse n'est pas retenue. L'indice 000 semble indiquer un seul rédacteur."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER?\n",
     "\n",
     "# matrice = pd.crosstab(form_df['text_id'], form_df['writer_id'])\n",
     "\n",
     "# fig = plt.figure(figsize = (12,8))\n",
     "# sns.heatmap(matrice**.2, cmap = 'viridis',cbar = False)\n",
     "# plt.title('Croisement entre textes et rédacteurs', fontsize=15);"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Cette visualisation en heatmap montre une matrice très diaginalisée en marches, ce qui veut dire que, globalement, chaque nouvel rédacteur à eu des nouveaux textes à réddiger. En conséquence, il n'y pas beaucoup de textes rédigés par différents rédacteurs."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Analyse des mots"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Représentation globale des mots"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "rd.show_50_random_words(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse du contraste des images mots"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "#### Images avec contraste nul"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "print('Nombre de mot dont l\\'image a un contraste nul : ', word_df[word_df['michelson_contrast'] == 0].shape[0])\n",
     "rd.show_images_with_contraste_0(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER?\n",
     "# plt.figure(figsize=(15,5))\n",
     "# sns.countplot(x='transcription', data = bad_contrast_df, order = bad_contrast_df.transcription.value_counts().index)\n",
     "# plt.title('Occurrence des images avec un contraste égale = 0')\n",
     "# plt.grid();"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Il a un total de 132 images avec une image de contraste nul avec un mélange de pontuaction et mots. Avant de retirer ces mots du dataset, on peut vérifier s'il apparaissent à d'autres indices du dataset pour s'assurer que leur représentativité n'est pas impactée."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_nb_words_having_some_contrast_0(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_contrast_distribution(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_min_max_contrast_images(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "L'image au contraste le plus petit reste lisible, nous pouvons ainsi considérer les autres images comme lisibles."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse du niveau de gris des lignes"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "<span style=\"color: red\">\n",
     "Warning : le gray_level du dataset initial correspond au gray_level de la ligne scannée et pas celui du mot.\n",
     "</span>"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "\n",
     "dv.show_gray_level_distribution(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Nous remarquons une concentration des niveaux de gris autour de la médiane (177) avec une déviation moyenne standard légère (seulement 13.8). \n",
     "\n",
     "Nous pouvons ainsi nous poser la question suivante : comment réagira notre modèle en présence de valeurs extrêmes traits légers aux couleurs claires et traits épaix aux couleurs sombres?"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "dv.show_min_max_gray_level_images(word_df)\n"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Les images du dataset sont toutes réalisées dans de bonnes conditions pour ce qui est du contraste entre le texte et le fond. Il n'y a pas de reliefs, de couleurs ou de motifs pouvant rendre l'extraction de texte difficile."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "#### Affichage global"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "rd.show_100max_gray_level_images(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "\n",
     "rd.show_100min_gray_level_images(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse du niveau de gris des mots"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_gray_level_per_word(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "#### Représentation globale"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "rd.show_75max_gray_level_word_images(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "rd.show_75min_gray_level_word_images(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER? 3 cellules suivantes\n",
     "\n",
     "### Mise en relation du niveau de gris d'une ligne et d'un mot"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "#from scipy.stats import pearsonr\n",
     "\n",
     "#pearsonr(df.gray_level, df.gray_level_mot)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "#plt.figure(figsize = (15,8))\n",
     "#sns.scatterplot(data=df[df['seg_res']==1], x='gray_level', y='gray_level_mot')\n",
     "#plt.title('Relation entre gray_level mot et gray_level ligne')\n",
     "#plt.grid()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse de la répartition des mots dans le corpus"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER?\n",
     "\n",
     "# %%time\n",
     "# matrice2 = pd.crosstab(df_temp['writer_id'], df_temp['transcription'])                                \n",
     "                                \n",
     "# fig = plt.figure(figsize = (20,12))\n",
     "# sns.heatmap(matrice2, cmap = 'viridis',cbar = False)\n",
     "# plt.title('Croisement entre mots et rédacteurs', fontsize=15);"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Analyse de la répartition des lettres dans le corpus"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_letters_occurences(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Nous pouvons observer une grosse disparité dans les représentations de chacune des lettres.\n",
     "Les lettres 'j', 'k', 'q', 'x' et 'z' notamment sont très peu représentées. \n",
     "\n",
     "A l'inverse, les lettres 'e', 'a' et 't' sont très présentes. \n",
     "\n"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_lower_letters_frequency(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Cette distribution peut être mise en paralèlle avec la distribution des lettres dans la langue anglaise. \n",
     "\n",
     "En effet, notre objectif étant de créer une reconnaissance de caractères, plus notre modèle aura l'habtiude de traiter des lettres fréquentes correctement, meilleures seront nos chances de réussite, à defaut d'avoir un dataset plus conséquent.\n",
     "\n",
     "Or, les fréquences des lettres anglaises semblent bien concordées avec la distribution de notre corpus. Le corpus est donc bien représentatif.\n",
     "\n",
     "<img src=\"../images/english_letter_distribution.png\" />\n",
     "\n",
     "Source: https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_letters_repartition_with_english(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "On peut par contre se demander comment réagirait notre modèle à une autre langue dont la répartition des lettres serait différente."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_upper_letters_frequency(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "On remarque cependant une sous représentation des majuscules dans le dataset. Les représentations des majuscules étant radicalement différentes des minuscules, il se peut que notre modèle manque de données d'entraînement pour, par la suite, bien distinguer des majuscules."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Longueur des mots"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Position et taille des boîtes\n",
     "\n",
     "```\n",
     "file n06-128.png\n",
     "```\n",
     "\n",
     "Output:\n",
     "`n06-128.png: PNG image data, 2479 x 3542, 8-bit grayscale, non-interlaced`\n"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Position des boîtes"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER??\n",
     "\n",
     "print(word_df['x'].max())\n",
     "print(word_df['y'].max())\n",
     "word_df[(word_df['x'] == -1) | (word_df['y'] == -1) | (word_df['h'] == -1) | (word_df['w'] == -1)].head()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Il ne reste plus de mots dont le positionnement n'a pas été trouver. Nous pouvons donc analyser la répartition des boîtes dans notre dataset."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A CONSERVER?? Ici?\n",
     "\n",
     "# Need ten minutes to run\n",
     "#dv.show_text_position_over_dataset(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "<img src=\"../images/text_box_position.png\">"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Taille des boîtes"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "\n",
     "dv.show_bounding_boxes_size(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A DEPLACER PLUS HAUT AVEC LE RESTE DES VISUS AVANT PREPROCESSING !!!\n",
     "\n",
     "rd.show_45max_box_size_nosegmented_words_images(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Ce résultat montre qu'il y a des mots mal segmentés. Besoin de trier uniquement sur les mots avec seg_res == 1."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# A DEPLACER PLUS HAUT AVEC LE RESTE DES VISUS AVANT PREPROCESSING !!!\n",
     "\n",
     "rd.show_45max_box_size_segmented_words_images(word_df)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "\n",
     "\n",
     "rd.show_100min_box_size_words_images(word_df)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Styles d'écriture"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Nous pouvons également nous intéresser aux différents styles d'écriture pouvant influencés la représentation d'une lettre. \n",
     "\n",
     "Nous pouvons supposer que chacun des rédacteurs a un style d'écriture qui lui est propre et nous intéresser aux nombres de styles existants pour chacune des lettres. \n",
     "\n",
     "Il serait par ailleurs peut être intéressant par la suite de générer des textes ayant différentes polices d'écriture pour diversifier davantage les représentations possibles d'une lettre."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
     "scrolled": false
    },
    "outputs": [],
    "source": []
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "importlib.reload(rss)\n",
     "importlib.reload(pp)\n",
     "importlib.reload(dv)\n",
     "importlib.reload(rd)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "La répartition du nombre de formulaires écrits par rédacteur n'est pas uniforme, il faudra donc être prudent lors de la création des ensembles de training, validation et test (ne prendre qu'un seul formulaire par rédacteur pour chaque ensemble par ex)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Analyse de la distributions des mots et caractères par rédacteur\n",
     "(titre à confirmer)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_words_repartition()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Beaucoup de mots ne sont vus qu'une seule fois, d'autres sont vus de très nombreuses fois, attention à l'overfitting"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_letters_per_word()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "dv.show_caracters_distribution_per_writer(df_all)"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Comme on pouvait s'y attendre, les lettres minuscules sont presque toutes au moins une fois représentées par un rédacteur. \n",
     "\n",
     "Nous voyons cependant que les lettres majuscules peuvent poser problème car elles ne sont parfois représentées que par moins de 100 rédacteurs différents."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "Nous aurions pu également compter le nombre d'occurences de ces lettres pour chaque rédacteur afin de nous assurer qu'un style ne domine pas sur les autres car majoritairement représenté. \n",
     "\n",
     "Toutefois, l'impact d'une surreprésentation devrait pouvoir être négligé car les textes comportent tous un bon nombre de lettres différentes."
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Luminance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "from PIL import Image\n",
     "\n",
     "img = Image.open(df.iloc[0].word_img_path)\n",
     "#Convert the image te RGB if it is a .gif for example\n",
     "img = img.convert ('RGB')\n",
     "#coordinates of the pixel\n",
     "X,Y = 0,0\n",
     "#Get RGB\n",
     "pixelRGB = img.getpixel((X,Y))\n",
     "R,G,B = pixelRGB \n",
     "\n",
     "brightness = sum([R,G,B])/3\n",
     "brightness"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## Détection des contours"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "import cv2\n",
     "import numpy as np\n",
     "from matplotlib import pyplot as plt\n",
     "\n",
     "\n",
     "\n",
     "img_arr = cv2.imread(df.iloc[0].word_img_path)\n",
     "gray = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
     "img = cv2.GaussianBlur(gray,(3,3),0)\n",
     "\n",
     "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
     "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0, ksize=5)  \n",
     "sobely = cv2.Sobel(img,cv2.CV_64F,0,1, ksize=5)  \n",
     "\n",
     "\n",
     "plt.subplot(2,2,1),\n",
     "plt.imshow(img,cmap = 'gray')\n",
     "plt.title('Original')\n",
     "plt.xticks([])\n",
     "plt.yticks([])\n",
     "\n",
     "plt.subplot(2,2,2),\n",
     "plt.imshow(laplacian,cmap = 'gray')\n",
     "plt.title('Laplacian')\n",
     "plt.xticks([])\n",
     "plt.yticks([])\n",
     "\n",
     "plt.subplot(2,2,3)\n",
     "plt.imshow(sobelx,cmap = 'gray')\n",
     "plt.title('Sobel X')\n",
     "plt.xticks([])\n",
     "plt.yticks([])\n",
     "\n",
     "plt.subplot(2,2,4)\n",
     "plt.imshow(sobely,cmap = 'gray')\n",
     "plt.title('Sobel Y')\n",
     "plt.xticks([])\n",
     "plt.yticks([])\n",
     "\n",
     "plt.show()"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "def get_laplacian_img_for_row(row):\n",
     "    img_arr = cv2.imread(row.word_img_path)\n",
     "    gray = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
     "    img = cv2.GaussianBlur(gray,(3,3),0)\n",
     "    return cv2.Laplacian(img,cv2.CV_64F)\n",
     "\n",
     "\n",
     "\n",
     "bad_contrast_row = df[df['michelson_contrast'] <= 0.2].iloc[0]\n",
     "laplacian_bad_constrast = get_laplacian_img_for_row(bad_contrast_row)\n",
     "print(bad_contrast_row.word_img_path)\n",
     "\n",
     "plt.subplot(1,2,1),\n",
     "plt.title('Image normale')\n",
     "plt.imshow(plt.imread(bad_contrast_row.word_img_path));\n",
     "plt.subplot(1,2,2),\n",
     "plt.imshow(laplacian_bad_constrast,cmap = 'gray');\n",
     "plt.title('Laplacien')\n",
     "plt.xticks([])\n",
     "plt.yticks([])\n",
     "plt.show()\n"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "first_writer_df = df[df['writer_id'] == '000']\n",
     "print(len(first_writer_df))\n",
     "print(len(df))"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "n_rows = 5\n",
     "n_col = 2\n",
     "n_images = n_rows * n_col\n",
     "rand_list = np.sort(np.random.randint(0, first_writer_df.shape[0], n_images))\n",
     "\n",
     "\n",
     "fig, ax = plt.subplots(n_rows,n_col, figsize=(14,50))\n",
     "for i in range(n_rows):\n",
     "    for j in range(n_col):\n",
     "        img = plt.imread(get_form_img_path_by_word_id(first_writer_df.word_id.iloc[rand_list[i+ j * n_col]]))\n",
     "        ax[i, j].imshow(img, cmap = 'gray') ;"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": []
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": []
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3.9.12 ('base')",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.9.12"
   },
   "vscode": {
    "interpreter": {
     "hash": "646607af5cee56728deff5007f5747c6b792545c0f7c2f22c37576bfe12603f2"
    }
   }
  },
  "nbformat": 4,
  "nbformat_minor": 2
 }