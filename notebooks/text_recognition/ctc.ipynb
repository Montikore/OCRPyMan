{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition with CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ctc_utils' from '/Users/jpec/Prog/OCRpyMAN/notebooks/text_recognition/ctc_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctc_utils as utils\n",
    "from importlib import reload \n",
    "import warnings\n",
    "\n",
    "# Ensure we have always the latest state and \n",
    "# not the last import in memory\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  96420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_img_path</th>\n",
       "      <th>word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-00.png</td>\n",
       "      <td>a01-000u-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-01.png</td>\n",
       "      <td>a01-000u-00-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-02.png</td>\n",
       "      <td>a01-000u-00-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription                                  word_img_path         word_id\n",
       "0             A  ../data/words/a01/a01-000u/a01-000u-00-00.png  a01-000u-00-00\n",
       "1          MOVE  ../data/words/a01/a01-000u/a01-000u-00-01.png  a01-000u-00-01\n",
       "2            to  ../data/words/a01/a01-000u/a01-000u-00-02.png  a01-000u-00-02"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = (32, 128)\n",
    "full_df = pd.read_pickle('../../pickle/df.pickle')\n",
    "print(\"Length: \", len(full_df))\n",
    "ctc_df = full_df[['transcription', 'word_img_path', 'word_id']]\n",
    "ctc_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "offset=75616\n",
    "# utils.generate_preprocessed_imgs_from_df(ctc_df, offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gray_img = cv2.imread('preprocessed_text_imgs/' + ctc_df.iloc[0].word_id + '.png', 0)\n",
    "plt.imshow(gray_img, cmap='gray');\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=75616\n",
    "\n",
    "df = ctc_df.iloc[:offset][['transcription', 'word_id']]\n",
    "df['img'] = df['word_id'].apply(lambda x: cv2.imread('preprocessed_text_imgs/' + x + '.png', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os.path import exists\n",
    "# ctc_df_path = '../../pickle/ctc_df.pickle'\n",
    "\n",
    "# if exists(ctc_df_path):\n",
    "#     df = pd.read_pickle(ctc_df_path)\n",
    "# else:\n",
    "#     ctc_df\n",
    "#     pickle.dump(ctc_df, open(ctc_df_path, \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_id</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop</td>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>a01-000u-00-04</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription         word_id  \\\n",
       "0             A  a01-000u-00-00   \n",
       "1          MOVE  a01-000u-00-01   \n",
       "2            to  a01-000u-00-02   \n",
       "3          stop  a01-000u-00-03   \n",
       "4           Mr.  a01-000u-00-04   \n",
       "\n",
       "                                                 img  \n",
       "0  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "1  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "2  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "3  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n",
       "4  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_id</th>\n",
       "      <th>img</th>\n",
       "      <th>clean_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop</td>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>a01-000u-00-04</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription         word_id  \\\n",
       "0             A  a01-000u-00-00   \n",
       "1          MOVE  a01-000u-00-01   \n",
       "2            to  a01-000u-00-02   \n",
       "3          stop  a01-000u-00-03   \n",
       "4           Mr.  a01-000u-00-04   \n",
       "\n",
       "                                                 img clean_trans  \n",
       "0  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...           A  \n",
       "1  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...        MOVE  \n",
       "2  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...          to  \n",
       "3  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...        stop  \n",
       "4  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...          Mr  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "char_list = list(string.ascii_letters)+[' '] \n",
    "\n",
    "def extract_allowed_chars_from_string(char_list, str):\n",
    "    res = ''\n",
    "    for letter in str:\n",
    "        if letter in char_list:\n",
    "            res += letter\n",
    "    return res\n",
    "\n",
    "df['clean_trans'] = df.transcription.apply(lambda x: extract_allowed_chars_from_string(char_list, x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille avant nettoyage: 75616\n",
      "Taille après nettoyage: 65192\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille avant nettoyage:\", len(df))\n",
    "df = df[(df['clean_trans'] != \"\") & (df['clean_trans'] == df['transcription'])]\n",
    "# df = df[df['clean_trans'] != \"\"]\n",
    "print(\"Taille après nettoyage:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transcription.apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Part\n",
    "\n",
    "\n",
    "The idea here is to cut our image into several features (could be interpreted as smaller areas of the picture).\n",
    "\n",
    "<img src=\"imgs/cnn_result.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we ill use a succession of \n",
    "- **Convolution** to extract\n",
    "- **Batch Normalization** to prevent our model from overfitting (equivalent of Dropout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch normalization\n",
    "\n",
    "TLDR: Solve **internal covariate shift** and simplify \n",
    "\n",
    "**Normalization** is a procedure to change the value of the numeric variable in the dataset to a typical scale, without misshaping contrasts in the range of value.\n",
    "\n",
    "**Batch normalization** is a technique for training very deep neural networks that normalizes the contributions to a layer for every mini-batch.\n",
    "\n",
    "In neural networks, the output of the first layer feeds into the second layer, the output of the second layer feeds into the third, and so on. When the parameters of a layer change, so does **the distribution of inputs to subsequent layers**.\n",
    "\n",
    "> We define Internal Covariate Shift as the change in the distribution of network activations due to the change in network parameters during training.\n",
    "\n",
    "These shifts in input distributions can be problematic for neural networks, especially deep neural networks that could have a large number of layers.\n",
    "\n",
    "Batch normalization is a method intended to mitigate internal covariate shift for neural networks.\n",
    "\n",
    "<img src=\"imgs/batch_normalization.jpeg\" />\n",
    "\n",
    "This has the impact of settling the learning process and drastically decreasing the number of training epochs required to train deep neural networks.\n",
    "\n",
    "Sources: \n",
    "- https://machinelearning.wtf/terms/internal-covariate-shift/\n",
    "- https://towardsdatascience.com/batch-normalisation-in-deep-neural-network-ce65dd9e8dbf#:~:text=Batch%20normalization%20solves%20a%20major,you%20can%20often%20remove%20dropout.\n",
    "- https://towardsdatascience.com/understanding-dataset-shift-f2a5a262a766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv\n",
    "\n",
    "<img src=\"imgs/conv_padding.gif\" />\n",
    "\n",
    "- Padding '**valid**' is the first figure. The filter window stays inside the image. When padding == \"VALID\", there can be a loss of information. Generally, elements on the right and the bottom of the image tend to be ignored. How many elements are ignored depends on the size of the kernel and the stride.\n",
    "\n",
    "- Padding '**same**' is the third figure. The output is the same size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling/Flattening\n",
    "\n",
    "**Pooling** is the process of merging. So it’s basically for the purpose of **reducing the size of the data**.\n",
    "\n",
    "<img src=\"imgs/pooling_flattening.png\" />\n",
    "\n",
    "**Flattening** is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector.\n",
    "\n",
    "Sources: \n",
    "\n",
    "- https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "\n",
    "hidden_layer_count = 256\n",
    "\n",
    "def build_sequential_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Layer 1\n",
    "    # (None, 32, 128, 64)\n",
    "    model.add(Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(5,5),\n",
    "            padding='SAME',\n",
    "            input_shape = (img_size[0], img_size[1], 1)\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    # (None, 16, 64, 64)\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    # (None, 8, 32, 128 -> nb conv filters)\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "\n",
    "\n",
    "    # Layer 4\n",
    "    # (None, 4, 32, 128)\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "\n",
    "    # Layer 5\n",
    "    # (None, 2, 32, 128)\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "    # (None, 1, 32, 256)\n",
    "    return model\n",
    "    \n",
    "# model = build_sequential_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have cut our entry image into X smaller parts. Those parts can be read as a time serie.\n",
    "\n",
    "Indeed, there is a strong connection between one part and the one coming after by construction (a word is a succession of letters).\n",
    "\n",
    "We can therefore make use of a **RNN** now in our model.\n",
    "\n",
    "NB: a part does not correspond exactly to a letter, it is more the idea behind it. It could be interesting to see the importance of the size of each part (number of cuts).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 09:05:21.244847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 128, 32)       832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 128, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 128, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 64, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 32, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 32, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 32, 128)        147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 32, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 32, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2, 32, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 32, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 32, 256)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32, 512)          789504    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32, 100)           51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,411,940\n",
      "Trainable params: 1,410,724\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Lambda\n",
    "\n",
    "model = build_sequential_model()\n",
    "model.add(Lambda(lambda x: tf.squeeze(x, axis=1)))\n",
    "# (None, 32, 256)\n",
    "# Bidirectionnal RNN\n",
    "model.add(Bidirectional(GRU(hidden_layer_count, return_sequences=True)))\n",
    "model.add(Dense(100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NotImplementedError: Cannot convert a symbolic Tensor (bidirectional_3/forward_gru_3/strided_slice:0) to a numpy array.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO LSTM could be a good idea ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c\n",
    "https://distill.pub/2017/ctc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectionist Temporal Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65192, 32, 128)\n",
      "(32, 128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "resized_imgs = np.array(df.img.values.tolist())\n",
    "resized_imgs = resized_imgs.reshape(-1, img_size[0], img_size[1])\n",
    "print(resized_imgs.shape)\n",
    "print(resized_imgs[0].shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(resized_imgs, df.clean_trans.values, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 7), dtype=string, numpy=\n",
       "array([[b't', b'h', b'e', b'', b'', b'', b''],\n",
       "       [b'o', b'f', b'', b'', b'', b'', b''],\n",
       "       [b'f', b'r', b'i', b'e', b'n', b'd', b's'],\n",
       "       [b'w', b'o', b'u', b'l', b'd', b'', b''],\n",
       "       [b'a', b's', b'k', b'e', b'd', b'', b'']], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_labels(labels, char_list):\n",
    "    # Hash Table\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            char_list,\n",
    "            np.arange(len(char_list)),\n",
    "            value_dtype=tf.int32\n",
    "        ),\n",
    "        -1,\n",
    "        name='char2id'\n",
    "    )\n",
    "    return table.lookup(\n",
    "    tf.compat.v1.string_split(labels, delimiter=''))\n",
    "\n",
    "def decode_codes(codes, charList):\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            np.arange(len(charList)),\n",
    "            charList,\n",
    "            key_dtype=tf.int32\n",
    "        ),\n",
    "        '',\n",
    "        name='id2char'\n",
    "    )\n",
    "    return table.lookup(codes)\n",
    "\n",
    "transcrip_test = y_train[:5]\n",
    "encoded_labels = encode_labels(transcrip_test, char_list)\n",
    "decoded_codes = decode_codes(encoded_labels, char_list)\n",
    "# print('transcrip_test', transcrip_test)\n",
    "# print('encoded_labels', encoded_labels)\n",
    "# print('-----------------')\n",
    "# print('decoded_codes', decoded_codes)\n",
    "\n",
    "tf.sparse.to_dense(decoded_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(X_train,-1), y_train))\n",
    "dataset = dataset.shuffle(1000).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.reduce_mean(\n",
    "            tf.nn.ctc_loss(\n",
    "                labels = labels,\n",
    "                logits = logits,\n",
    "                logit_length = [logits.shape[1]]*logits.shape[0],\n",
    "                label_length = None,\n",
    "                logits_time_major = False,\n",
    "                blank_index=-1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "def train_op(model, optimizer, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Prédiction de notre modèle\n",
    "        y_pred = model(inputs, training=True)\n",
    "        # Calcule de l'erreur de notre modèle\n",
    "        loss_value = tf.reduce_mean(loss(targets, y_pred))\n",
    "    # Calculer le gradient de la fonction de perte\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    # Descente de gradient\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Retourner la valeur de la fonction de perte\n",
    "    return loss_value.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "epochs = 5\n",
    "\n",
    "# Entraînement du modèle\n",
    "for i in range(epochs): \n",
    "    # Pour chaque epoch\n",
    "    print('---- Epoch', i, '----')\n",
    "    j = 0\n",
    "    for X_b, y_b in dataset:\n",
    "\n",
    "        try :\n",
    "            y_ba = encode_labels(y_b, char_list)\n",
    "            print(\"Batch {}\".format(j), train_op(model, optimizer, X_b, y_ba))\n",
    "        except :\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            time.sleep(0.5)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'the'),\n",
       " ('news', 'news'),\n",
       " ('f', 'of'),\n",
       " ('mary', 'many'),\n",
       " ('Press', 'Press'),\n",
       " ('the', 'the'),\n",
       " ('coull', 'could'),\n",
       " ('there', 'there'),\n",
       " ('rake', 'rate'),\n",
       " ('one', 'one')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greedy_decoder(logits):\n",
    "    # ctc beam search decoder\n",
    "    predicted_codes, _ = tf.nn.ctc_greedy_decoder(\n",
    "        # shape of tensor [max_time x batch_size x num_classes] \n",
    "        tf.transpose(logits, (1, 0, 2)),\n",
    "        [logits.shape[1]]*logits.shape[0]\n",
    "    )\n",
    "    # convert to int32\n",
    "    codes = tf.cast(predicted_codes[0], tf.int32)\n",
    "    # Decode the index of caracter\n",
    "    text = decode_codes(codes, char_list)\n",
    "    # Convert a SparseTensor to string\n",
    "    text = tf.sparse.to_dense(text).numpy().astype(str)\n",
    "    return list(map(lambda x: ''.join(x), text))\n",
    "\n",
    "predicted_transcriptions = greedy_decoder(model(np.expand_dims(X_test[:10], -1)))\n",
    "list(zip(predicted_transcriptions, y_test[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Add english language corrector as an option\n",
    "- See with different slicing (not 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ctc_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ctc_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ctc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"ctc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = greedy_decoder(model(np.expand_dims(X_test, -1), training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = list(zip(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'the'),\n",
       " ('news', 'news'),\n",
       " ('of', 'f'),\n",
       " ('many', 'mary'),\n",
       " ('Press', 'Press'),\n",
       " ('the', 'the'),\n",
       " ('could', 'coull'),\n",
       " ('there', 'there'),\n",
       " ('rate', 'rake'),\n",
       " ('one', 'one')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    real predicted\n",
       "0    the       the\n",
       "1   news      news\n",
       "2     of         f\n",
       "3   many      mary\n",
       "4  Press     Press"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(data=np.array(eval_data), columns=['real', 'predicted'])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6520"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/evaluating-ocr-output-quality-with-character-error-rate-cer-and-word-error-rate-wer-853175297510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Error Rate (CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s, t):\n",
    "    m, n = len(s) + 1, len(t) + 1\n",
    "    d = [[0] * n for _ in range(m)]\n",
    "\n",
    "    for i in range(1, m):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(1, n):\n",
    "        d[0][j] = j\n",
    "\n",
    "    for j in range(1, n):\n",
    "        for i in range(1, m):\n",
    "            substitution_cost = 0 if s[i - 1] == t[j - 1] else 1\n",
    "            d[i][j] = min(d[i - 1][j] + 1,\n",
    "                          d[i][j - 1] + 1,\n",
    "                          d[i - 1][j - 1] + substitution_cost)\n",
    "\n",
    "    return d[m - 1][n - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(levenshtein_distance(\"Toto\", \"Tut\"))\n",
    "print(levenshtein_distance(\"Bonjour\", \"Bonnrouuj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_character_level_accuracy(original, predicted):\n",
    "    original_length = len(original)\n",
    "    if original_length == 0:\n",
    "        return 1\n",
    "    distance = levenshtein_distance(original, predicted)\n",
    "    if distance > original_length:\n",
    "        return 0\n",
    "    return 1 - (distance / original_length)\n",
    "\n",
    "eval_df['cer'] = [evaluate_character_level_accuracy(row.real, row.predicted) for index, row in eval_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "      <th>cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>f</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>mary</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    real predicted   cer\n",
       "0    the       the  1.00\n",
       "1   news      news  1.00\n",
       "2     of         f  0.50\n",
       "3   many      mary  0.75\n",
       "4  Press     Press  1.00"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notre modèle a une précision par mot de 0.7794853689255536\n"
     ]
    }
   ],
   "source": [
    "print(\"Notre modèle a une précision par mot de\", eval_df['cer'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Error Rate (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_id</th>\n",
       "      <th>img</th>\n",
       "      <th>clean_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop</td>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaitskell</td>\n",
       "      <td>a01-000u-00-05</td>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>Gaitskell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription         word_id  \\\n",
       "0             A  a01-000u-00-00   \n",
       "1          MOVE  a01-000u-00-01   \n",
       "2            to  a01-000u-00-02   \n",
       "3          stop  a01-000u-00-03   \n",
       "5     Gaitskell  a01-000u-00-05   \n",
       "\n",
       "                                                 img clean_trans  \n",
       "0  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...           A  \n",
       "1  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...        MOVE  \n",
       "2  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...          to  \n",
       "3  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...        stop  \n",
       "5  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   Gaitskell  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d35786cd2f650d46a54538d5478b9f72cd10ae51458c3726c4e0b827258ea8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
