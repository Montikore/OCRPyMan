{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition with CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/45/1rh915g935nggkhvq3fhbn180000gn/T/ipykernel_41519/876068771.py\", line 7, in <cell line: 7>\n",
      "    reload(utils)\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/jpec/Prog/OCRpyMAN/notebooks/text_recognition/ctc_utils.py\", line 12, in <module>\n",
      "    from tqdm import tqdm\n",
      "ModuleNotFoundError: No module named 'tqdm'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import ctc_utils as utils\n",
    "from importlib import reload \n",
    "import warnings\n",
    "\n",
    "# Ensure we have always the latest state and \n",
    "# not the last import in memory\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (32, 128)\n",
    "# data = pd.read_pickle('../../pickle/letter_detection_data.pickle')\n",
    "# df = data['df']\n",
    "# preprocessed_imgs = data['preprocessed_imgs']\n",
    "\n",
    "# print(\"Length: \", len(df))\n",
    "# print(\"Imgs length: \", len(preprocessed_imgs))\n",
    "# print(\"Img shape: \", preprocessed_imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  96420\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_img_path</th>\n",
       "      <th>word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-00.png</td>\n",
       "      <td>a01-000u-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-01.png</td>\n",
       "      <td>a01-000u-00-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>../data/words/a01/a01-000u/a01-000u-00-02.png</td>\n",
       "      <td>a01-000u-00-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcription                                  word_img_path         word_id\n",
       "0             A  ../data/words/a01/a01-000u/a01-000u-00-00.png  a01-000u-00-00\n",
       "1          MOVE  ../data/words/a01/a01-000u/a01-000u-00-01.png  a01-000u-00-01\n",
       "2            to  ../data/words/a01/a01-000u/a01-000u-00-02.png  a01-000u-00-02"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_pickle('../../pickle/df.pickle')\n",
    "print(\"Length: \", len(full_df))\n",
    "ctc_df = full_df[['transcription', 'word_img_path', 'word_id']]\n",
    "ctc_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11252it [1:38:23,  1.60s/it]"
     ]
    }
   ],
   "source": [
    "reload(utils)\n",
    "\n",
    "utils.generate_preprocessed_imgs_from_df(ctc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "ctc_df_path = '../../pickle/ctc_df.pickle'\n",
    "\n",
    "if exists(ctc_df_path):\n",
    "    df = pd.read_pickle(ctc_df_path)\n",
    "else:\n",
    "    \n",
    "    pickle.dump(df, open(ctc_df_path, \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>michelson_contrast</th>\n",
       "      <th>gray_level_mot</th>\n",
       "      <th>word_id</th>\n",
       "      <th>gray_level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_img_path</th>\n",
       "      <th>form_img_path</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>944</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.889522</td>\n",
       "      <td>a01-020u-06-05</td>\n",
       "      <td>170</td>\n",
       "      <td>1954</td>\n",
       "      <td>1831</td>\n",
       "      <td>389</td>\n",
       "      <td>100</td>\n",
       "      <td>studying</td>\n",
       "      <td>../data/words/a01/a01-020u/a01-020u-06-05.png</td>\n",
       "      <td>../data/formsA-D/a01-020u.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>914</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.774799</td>\n",
       "      <td>a01-020u-02-06</td>\n",
       "      <td>169</td>\n",
       "      <td>1565</td>\n",
       "      <td>1129</td>\n",
       "      <td>128</td>\n",
       "      <td>49</td>\n",
       "      <td>has</td>\n",
       "      <td>../data/words/a01/a01-020u/a01-020u-02-06.png</td>\n",
       "      <td>../data/formsA-D/a01-020u.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>581</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.830613</td>\n",
       "      <td>a01-011u-04-05</td>\n",
       "      <td>166</td>\n",
       "      <td>1622</td>\n",
       "      <td>1472</td>\n",
       "      <td>321</td>\n",
       "      <td>62</td>\n",
       "      <td>discuss</td>\n",
       "      <td>../data/words/a01/a01-011u/a01-011u-04-05.png</td>\n",
       "      <td>../data/formsA-D/a01-011u.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>357</td>\n",
       "      <td>0.746575</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>a01-007u-00-00</td>\n",
       "      <td>165</td>\n",
       "      <td>402</td>\n",
       "      <td>772</td>\n",
       "      <td>233</td>\n",
       "      <td>60</td>\n",
       "      <td>Since</td>\n",
       "      <td>../data/words/a01/a01-007u/a01-007u-00-00.png</td>\n",
       "      <td>../data/formsA-D/a01-007u.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.810634</td>\n",
       "      <td>a01-003u-06-07</td>\n",
       "      <td>163</td>\n",
       "      <td>2162</td>\n",
       "      <td>1888</td>\n",
       "      <td>155</td>\n",
       "      <td>69</td>\n",
       "      <td>put</td>\n",
       "      <td>../data/words/a01/a01-003u/a01-003u-06-07.png</td>\n",
       "      <td>../data/formsA-D/a01-003u.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  michelson_contrast  gray_level_mot         word_id  gray_level  \\\n",
       "0    944            0.758621        0.889522  a01-020u-06-05         170   \n",
       "1    914            0.695946        0.774799  a01-020u-02-06         169   \n",
       "2    581            0.683168        0.830613  a01-011u-04-05         166   \n",
       "3    357            0.746575        0.817196  a01-007u-00-00         165   \n",
       "4    200            0.767606        0.810634  a01-003u-06-07         163   \n",
       "\n",
       "      x     y    w    h transcription  \\\n",
       "0  1954  1831  389  100      studying   \n",
       "1  1565  1129  128   49           has   \n",
       "2  1622  1472  321   62       discuss   \n",
       "3   402   772  233   60         Since   \n",
       "4  2162  1888  155   69           put   \n",
       "\n",
       "                                   word_img_path  \\\n",
       "0  ../data/words/a01/a01-020u/a01-020u-06-05.png   \n",
       "1  ../data/words/a01/a01-020u/a01-020u-02-06.png   \n",
       "2  ../data/words/a01/a01-011u/a01-011u-04-05.png   \n",
       "3  ../data/words/a01/a01-007u/a01-007u-00-00.png   \n",
       "4  ../data/words/a01/a01-003u/a01-003u-06-07.png   \n",
       "\n",
       "                   form_img_path  length  \n",
       "0  ../data/formsA-D/a01-020u.png       8  \n",
       "1  ../data/formsA-D/a01-020u.png       3  \n",
       "2  ../data/formsA-D/a01-011u.png       7  \n",
       "3  ../data/formsA-D/a01-007u.png       5  \n",
       "4  ../data/formsA-D/a01-003u.png       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Part\n",
    "\n",
    "\n",
    "The idea here is to cut our image into several features (could be interpreted as smaller areas of the picture).\n",
    "\n",
    "<img src=\"imgs/cnn_result.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we ill use a succession of \n",
    "- **Convolution** to extract\n",
    "- **Batch Normalization** to prevent our model from overfitting (equivalent of Dropout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch normalization\n",
    "\n",
    "TLDR: Solve **internal covariate shift** and simplify \n",
    "\n",
    "**Normalization** is a procedure to change the value of the numeric variable in the dataset to a typical scale, without misshaping contrasts in the range of value.\n",
    "\n",
    "**Batch normalization** is a technique for training very deep neural networks that normalizes the contributions to a layer for every mini-batch.\n",
    "\n",
    "In neural networks, the output of the first layer feeds into the second layer, the output of the second layer feeds into the third, and so on. When the parameters of a layer change, so does **the distribution of inputs to subsequent layers**.\n",
    "\n",
    "> We define Internal Covariate Shift as the change in the distribution of network activations due to the change in network parameters during training.\n",
    "\n",
    "These shifts in input distributions can be problematic for neural networks, especially deep neural networks that could have a large number of layers.\n",
    "\n",
    "Batch normalization is a method intended to mitigate internal covariate shift for neural networks.\n",
    "\n",
    "<img src=\"imgs/batch_normalization.jpeg\" />\n",
    "\n",
    "This has the impact of settling the learning process and drastically decreasing the number of training epochs required to train deep neural networks.\n",
    "\n",
    "Sources: \n",
    "- https://machinelearning.wtf/terms/internal-covariate-shift/\n",
    "- https://towardsdatascience.com/batch-normalisation-in-deep-neural-network-ce65dd9e8dbf#:~:text=Batch%20normalization%20solves%20a%20major,you%20can%20often%20remove%20dropout.\n",
    "- https://towardsdatascience.com/understanding-dataset-shift-f2a5a262a766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv\n",
    "\n",
    "<img src=\"imgs/conv_padding.gif\" />\n",
    "\n",
    "- Padding '**valid**' is the first figure. The filter window stays inside the image. When padding == \"VALID\", there can be a loss of information. Generally, elements on the right and the bottom of the image tend to be ignored. How many elements are ignored depends on the size of the kernel and the stride.\n",
    "\n",
    "- Padding '**same**' is the third figure. The output is the same size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling/Flattening\n",
    "\n",
    "**Pooling** is the process of merging. So it’s basically for the purpose of **reducing the size of the data**.\n",
    "\n",
    "<img src=\"imgs/pooling_flattening.png\" />\n",
    "\n",
    "**Flattening** is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector.\n",
    "\n",
    "Sources: \n",
    "\n",
    "- https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 128, 32)       832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 128, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 128, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 64, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 32, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 32, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 32, 128)        147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 32, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 32, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 2, 32, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 32, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571,136\n",
      "Trainable params: 569,920\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 16:04:38.103287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "\n",
    "hidden_layer_count = 256\n",
    "\n",
    "def build_sequential_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Layer 1\n",
    "    # (None, 32, 128, 64)\n",
    "    model.add(Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(5,5),\n",
    "            padding='SAME',\n",
    "            input_shape = (img_size[0], img_size[1], 1)\n",
    "        )\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    # (None, 16, 64, 64)\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    # (None, 8, 32, 128 -> nb conv filters)\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "\n",
    "\n",
    "    # Layer 4\n",
    "    # (None, 4, 32, 128)\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "\n",
    "    # Layer 5\n",
    "    # (None, 2, 32, 128)\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(2,1), strides=(2,1)))\n",
    "    # (None, 1, 32, 256)\n",
    "    return model\n",
    "    \n",
    "# model = build_sequential_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have cut our entry image into X smaller parts. Those parts can be read as a time serie.\n",
    "\n",
    "Indeed, there is a strong connection between one part and the one coming after by construction (a word is a succession of letters).\n",
    "\n",
    "We can therefore make use of a **RNN** now in our model.\n",
    "\n",
    "NB: a part does not correspond exactly to a letter, it is more the idea behind it. It could be interesting to see the importance of the size of each part (number of cuts).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 32, 128, 32)       832       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 128, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 128, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 64, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 32, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 32, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 8, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 32, 128)        147584    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 4, 32, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 2, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 2, 32, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 2, 32, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 2, 32, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 32, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 32, 256)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 32, 512)          789504    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32, 100)           51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,411,940\n",
      "Trainable params: 1,410,724\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Lambda\n",
    "\n",
    "model = build_sequential_model()\n",
    "model.add(Lambda(lambda x: tf.squeeze(x, axis=1)))\n",
    "# (None, 32, 256)\n",
    "# Bidirectionnal RNN\n",
    "model.add(Bidirectional(GRU(hidden_layer_count, return_sequences=True)))\n",
    "model.add(Dense(100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NotImplementedError: Cannot convert a symbolic Tensor (bidirectional_3/forward_gru_3/strided_slice:0) to a numpy array.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO LSTM could be a good idea ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c\n",
    "https://distill.pub/2017/ctc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectionist Temporal Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>michelson_contrast</th>\n",
       "      <th>gray_level_mot</th>\n",
       "      <th>word_id</th>\n",
       "      <th>gray_level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_img_path</th>\n",
       "      <th>form_img_path</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>944</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.889522</td>\n",
       "      <td>a01-020u-06-05</td>\n",
       "      <td>170</td>\n",
       "      <td>1954</td>\n",
       "      <td>1831</td>\n",
       "      <td>389</td>\n",
       "      <td>100</td>\n",
       "      <td>studying</td>\n",
       "      <td>../data/words/a01/a01-020u/a01-020u-06-05.png</td>\n",
       "      <td>../data/formsA-D/a01-020u.png</td>\n",
       "      <td>8</td>\n",
       "      <td>studying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>914</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.774799</td>\n",
       "      <td>a01-020u-02-06</td>\n",
       "      <td>169</td>\n",
       "      <td>1565</td>\n",
       "      <td>1129</td>\n",
       "      <td>128</td>\n",
       "      <td>49</td>\n",
       "      <td>has</td>\n",
       "      <td>../data/words/a01/a01-020u/a01-020u-02-06.png</td>\n",
       "      <td>../data/formsA-D/a01-020u.png</td>\n",
       "      <td>3</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>581</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.830613</td>\n",
       "      <td>a01-011u-04-05</td>\n",
       "      <td>166</td>\n",
       "      <td>1622</td>\n",
       "      <td>1472</td>\n",
       "      <td>321</td>\n",
       "      <td>62</td>\n",
       "      <td>discuss</td>\n",
       "      <td>../data/words/a01/a01-011u/a01-011u-04-05.png</td>\n",
       "      <td>../data/formsA-D/a01-011u.png</td>\n",
       "      <td>7</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>357</td>\n",
       "      <td>0.746575</td>\n",
       "      <td>0.817196</td>\n",
       "      <td>a01-007u-00-00</td>\n",
       "      <td>165</td>\n",
       "      <td>402</td>\n",
       "      <td>772</td>\n",
       "      <td>233</td>\n",
       "      <td>60</td>\n",
       "      <td>Since</td>\n",
       "      <td>../data/words/a01/a01-007u/a01-007u-00-00.png</td>\n",
       "      <td>../data/formsA-D/a01-007u.png</td>\n",
       "      <td>5</td>\n",
       "      <td>Since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.810634</td>\n",
       "      <td>a01-003u-06-07</td>\n",
       "      <td>163</td>\n",
       "      <td>2162</td>\n",
       "      <td>1888</td>\n",
       "      <td>155</td>\n",
       "      <td>69</td>\n",
       "      <td>put</td>\n",
       "      <td>../data/words/a01/a01-003u/a01-003u-06-07.png</td>\n",
       "      <td>../data/formsA-D/a01-003u.png</td>\n",
       "      <td>3</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  michelson_contrast  gray_level_mot         word_id  gray_level  \\\n",
       "0    944            0.758621        0.889522  a01-020u-06-05         170   \n",
       "1    914            0.695946        0.774799  a01-020u-02-06         169   \n",
       "2    581            0.683168        0.830613  a01-011u-04-05         166   \n",
       "3    357            0.746575        0.817196  a01-007u-00-00         165   \n",
       "4    200            0.767606        0.810634  a01-003u-06-07         163   \n",
       "\n",
       "      x     y    w    h transcription  \\\n",
       "0  1954  1831  389  100      studying   \n",
       "1  1565  1129  128   49           has   \n",
       "2  1622  1472  321   62       discuss   \n",
       "3   402   772  233   60         Since   \n",
       "4  2162  1888  155   69           put   \n",
       "\n",
       "                                   word_img_path  \\\n",
       "0  ../data/words/a01/a01-020u/a01-020u-06-05.png   \n",
       "1  ../data/words/a01/a01-020u/a01-020u-02-06.png   \n",
       "2  ../data/words/a01/a01-011u/a01-011u-04-05.png   \n",
       "3  ../data/words/a01/a01-007u/a01-007u-00-00.png   \n",
       "4  ../data/words/a01/a01-003u/a01-003u-06-07.png   \n",
       "\n",
       "                   form_img_path  length clean_trans  \n",
       "0  ../data/formsA-D/a01-020u.png       8    studying  \n",
       "1  ../data/formsA-D/a01-020u.png       3         has  \n",
       "2  ../data/formsA-D/a01-011u.png       7     discuss  \n",
       "3  ../data/formsA-D/a01-007u.png       5       Since  \n",
       "4  ../data/formsA-D/a01-003u.png       3         put  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "char_list = list(string.ascii_letters)+[' '] \n",
    "\n",
    "def extract_allowed_chars_from_string(char_list, str):\n",
    "    res = ''\n",
    "    for letter in str:\n",
    "        if letter in char_list:\n",
    "            res += letter\n",
    "    return res\n",
    "\n",
    "df['clean_trans'] = df.transcription.apply(lambda x: extract_allowed_chars_from_string(char_list, x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "resized_imgs = preprocessed_imgs.reshape(-1, img_size[0], img_size[1])\n",
    "print(resized_imgs.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(resized_imgs, df.clean_trans.values, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcrip_test ['meeting' 'Congress' 'Colonial' 'to' 'the']\n",
      "encoded_labels SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [0 4]\n",
      " [0 5]\n",
      " [0 6]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [1 5]\n",
      " [1 6]\n",
      " [1 7]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 6]\n",
      " [2 7]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [4 2]], shape=(28, 2), dtype=int64), values=tf.Tensor(\n",
      "[12  4  4 19  8 13  6 28 14 13  6 17  4 18 18 28 14 11 14 13  8  0 11 19\n",
      " 14 19  7  4], shape=(28,), dtype=int32), dense_shape=tf.Tensor([5 8], shape=(2,), dtype=int64))\n",
      "-----------------\n",
      "decoded_codes SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [0 3]\n",
      " [0 4]\n",
      " [0 5]\n",
      " [0 6]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [1 5]\n",
      " [1 6]\n",
      " [1 7]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 6]\n",
      " [2 7]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [4 2]], shape=(28, 2), dtype=int64), values=tf.Tensor(\n",
      "[b'm' b'e' b'e' b't' b'i' b'n' b'g' b'C' b'o' b'n' b'g' b'r' b'e' b's'\n",
      " b's' b'C' b'o' b'l' b'o' b'n' b'i' b'a' b'l' b't' b'o' b't' b'h' b'e'], shape=(28,), dtype=string), dense_shape=tf.Tensor([5 8], shape=(2,), dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 8), dtype=string, numpy=\n",
       "array([[b'm', b'e', b'e', b't', b'i', b'n', b'g', b''],\n",
       "       [b'C', b'o', b'n', b'g', b'r', b'e', b's', b's'],\n",
       "       [b'C', b'o', b'l', b'o', b'n', b'i', b'a', b'l'],\n",
       "       [b't', b'o', b'', b'', b'', b'', b'', b''],\n",
       "       [b't', b'h', b'e', b'', b'', b'', b'', b'']], dtype=object)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_labels(labels, char_list):\n",
    "    # Hash Table\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            char_list,\n",
    "            np.arange(len(char_list)),\n",
    "            value_dtype=tf.int32\n",
    "        ),\n",
    "        -1,\n",
    "        name='char2id'\n",
    "    )\n",
    "    return table.lookup(\n",
    "    tf.compat.v1.string_split(labels, delimiter=''))\n",
    "\n",
    "def decode_codes(codes, charList):\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            np.arange(len(charList)),\n",
    "            charList,\n",
    "            key_dtype=tf.int32\n",
    "        ),\n",
    "        '',\n",
    "        name='id2char'\n",
    "    )\n",
    "    return table.lookup(codes)\n",
    "\n",
    "transcrip_test = y_train[:5]\n",
    "encoded_labels = encode_labels(transcrip_test, char_list)\n",
    "decoded_codes = decode_codes(encoded_labels, char_list)\n",
    "print('transcrip_test', transcrip_test)\n",
    "print('encoded_labels', encoded_labels)\n",
    "print('-----------------')\n",
    "print('decoded_codes', decoded_codes)\n",
    "\n",
    "tf.sparse.to_dense(decoded_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(X_train,-1), y_train))\n",
    "dataset = dataset.shuffle(1000).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.reduce_mean(\n",
    "            tf.nn.ctc_loss(\n",
    "                labels = labels,\n",
    "                logits = logits,\n",
    "                logit_length = [logits.shape[1]]*logits.shape[0],\n",
    "                label_length = None,\n",
    "                logits_time_major = False,\n",
    "                blank_index=-1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        \n",
    "def train_op(model, optimizer, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Prédiction de notre modèle\n",
    "        y_pred = model(inputs, training=True)\n",
    "        # Calcule de l'erreur de notre modèle\n",
    "        loss_value = tf.reduce_mean(loss(targets, y_pred))\n",
    "       \n",
    "    # Calculer le gradient de la fonction de perte\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    # Descente de gradient\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Retourner la valeur de la fonction de perte\n",
    "    return loss_value.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Batch 0 14.908546\n",
      "Batch 1 13.797148\n",
      "Batch 2 12.310874\n",
      "Batch 3 13.523983\n",
      "Batch 4 12.716388\n",
      "Batch 5 13.529551\n",
      "Batch 6 13.058186\n",
      "Batch 7 11.762482\n",
      "Batch 8 12.022669\n",
      "Batch 9 13.708242\n",
      "Batch 10 12.919116\n",
      "Batch 11 12.013939\n",
      "Batch 12 12.237228\n",
      "Batch 13 11.8152685\n",
      "Batch 14 10.614099\n",
      "---- Epoch 1 ----\n",
      "Batch 0 11.830199\n",
      "Batch 1 12.390379\n",
      "Batch 2 12.108862\n",
      "Batch 3 12.791401\n",
      "Batch 4 11.464293\n",
      "Batch 5 15.061083\n",
      "Batch 6 11.8678465\n",
      "Batch 7 13.125231\n",
      "Batch 8 13.699672\n",
      "Batch 9 12.20892\n",
      "Batch 10 12.323076\n",
      "Batch 11 11.666872\n",
      "Batch 12 11.606966\n",
      "Batch 13 12.071641\n",
      "Batch 14 10.583216\n",
      "---- Epoch 2 ----\n",
      "Batch 0 13.369407\n",
      "Batch 1 10.80093\n",
      "Batch 2 13.413527\n",
      "Batch 3 11.385896\n",
      "Batch 4 10.460476\n",
      "Batch 5 11.662494\n",
      "Batch 6 14.186923\n",
      "Batch 7 13.483528\n",
      "Batch 8 11.593671\n",
      "Batch 9 12.272942\n",
      "Batch 10 10.875294\n",
      "Unexpected error: <class 'KeyboardInterrupt'>\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fa0a8c14610>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/backend.py\", line 4770, in <genexpr>\n",
      "    ta.write(ta_index_to_write, out)  File \"/Users/jpec/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "Batch 12 11.482777\n",
      "Batch 13 11.795727\n",
      "Batch 14 27.7961\n",
      "---- Epoch 3 ----\n",
      "Batch 0 11.862558\n",
      "Batch 1 12.561652\n",
      "Batch 2 12.296188\n",
      "Batch 3 11.620081\n",
      "Batch 4 11.490357\n",
      "Batch 5 12.579735\n",
      "Batch 6 12.244383\n",
      "Batch 7 11.543214\n",
      "Batch 8 11.910669\n",
      "Batch 9 11.19595\n",
      "Batch 10 11.849921\n",
      "Batch 11 12.063998\n",
      "Batch 12 11.917813\n",
      "Batch 13 12.864733\n",
      "Batch 14 8.837267\n",
      "---- Epoch 4 ----\n",
      "Batch 0 11.660355\n",
      "Batch 1 12.261016\n",
      "Batch 2 11.348782\n",
      "Batch 3 11.724537\n",
      "Batch 4 11.130857\n",
      "Batch 5 12.487126\n",
      "Batch 6 13.686388\n",
      "Batch 7 9.92009\n",
      "Batch 8 11.539026\n",
      "Batch 9 11.616659\n",
      "Batch 10 10.6579485\n",
      "Batch 11 10.866302\n",
      "Batch 12 11.380062\n",
      "Batch 13 11.989815\n",
      "Batch 14 14.186012\n",
      "---- Epoch 5 ----\n",
      "Batch 0 11.280893\n",
      "Batch 1 11.491388\n",
      "Batch 2 11.086722\n",
      "Batch 3 10.958655\n",
      "Batch 4 9.821985\n",
      "Batch 5 11.885987\n",
      "Batch 6 11.384075\n",
      "Batch 7 10.399118\n",
      "Batch 8 12.138801\n",
      "Batch 9 10.6719055\n",
      "Batch 10 11.462846\n",
      "Batch 11 11.786582\n",
      "Batch 12 12.194158\n",
      "Batch 13 11.611576\n",
      "Batch 14 7.8012333\n",
      "---- Epoch 6 ----\n",
      "Batch 0 10.375158\n",
      "Batch 1 10.531841\n",
      "Batch 2 10.756516\n",
      "Batch 3 9.801886\n",
      "Batch 4 11.004015\n",
      "Batch 5 12.250963\n",
      "Batch 6 11.40045\n",
      "Batch 7 11.471165\n",
      "Batch 8 11.636353\n",
      "Batch 9 11.728199\n",
      "Batch 10 9.892672\n",
      "Batch 11 11.342569\n",
      "Batch 12 10.564355\n",
      "Batch 13 11.111572\n",
      "Batch 14 14.287366\n",
      "---- Epoch 7 ----\n",
      "Batch 0 10.163181\n",
      "Batch 1 11.304848\n",
      "Batch 2 10.119577\n",
      "Batch 3 12.654219\n",
      "Batch 4 10.291597\n",
      "Batch 5 10.612379\n",
      "Batch 6 9.569267\n",
      "Batch 7 9.507959\n",
      "Batch 8 10.9491625\n",
      "Batch 9 10.509123\n",
      "Batch 10 12.115337\n",
      "Batch 11 10.515623\n",
      "Batch 12 11.323291\n",
      "Batch 13 9.875159\n",
      "Batch 14 13.163742\n",
      "---- Epoch 8 ----\n",
      "Batch 0 9.47501\n",
      "Batch 1 10.654675\n",
      "Batch 2 10.014299\n",
      "Batch 3 10.933932\n",
      "Batch 4 10.163876\n",
      "Batch 5 10.866984\n",
      "Batch 6 9.224513\n",
      "Batch 7 10.375603\n",
      "Batch 8 10.342821\n",
      "Batch 9 11.243144\n",
      "Batch 10 10.230323\n",
      "Batch 11 10.879605\n",
      "Batch 12 11.933432\n",
      "Batch 13 9.457495\n",
      "Batch 14 10.207605\n",
      "---- Epoch 9 ----\n",
      "Batch 0 10.79027\n",
      "Batch 1 10.921526\n",
      "Batch 2 11.284243\n",
      "Batch 3 10.780552\n",
      "Batch 4 9.985056\n",
      "Batch 5 10.1179085\n",
      "Batch 6 9.640167\n",
      "Batch 7 11.292603\n",
      "Batch 8 9.872951\n",
      "Batch 9 9.887806\n",
      "Batch 10 10.07719\n",
      "Batch 11 9.842451\n",
      "Batch 12 8.804389\n",
      "Batch 13 9.584396\n",
      "Batch 14 8.0444975\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "epochs = 10\n",
    "\n",
    "# Entraînenement du modèle\n",
    "for i in range(epochs): \n",
    "    # Pour chaque epoch\n",
    "    print('---- Epoch', i, '----')\n",
    "    j = 0\n",
    "    for X_b, y_b in dataset:\n",
    "\n",
    "        try :\n",
    "            y_ba = encode_labels(y_b, char_list)\n",
    "            print(\"Batch {}\".format(j), train_op(model, optimizer, X_b, y_ba))\n",
    "        except :\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            time.sleep(0.5)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'conference'),\n",
       " ('', 'the'),\n",
       " ('', 'Independence'),\n",
       " ('', 'and'),\n",
       " ('', 'turn'),\n",
       " ('', 'chief'),\n",
       " ('', 'together'),\n",
       " ('', 'Chiefs'),\n",
       " ('', 'Most'),\n",
       " ('', 'up')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greedy_decoder(logits):\n",
    "    # ctc beam search decoder\n",
    "    predicted_codes, _ = tf.nn.ctc_greedy_decoder(\n",
    "        # shape of tensor [max_time x batch_size x num_classes] \n",
    "        tf.transpose(logits, (1, 0, 2)),\n",
    "        [logits.shape[1]]*logits.shape[0]\n",
    "    )\n",
    "    \n",
    "    # convert to int32\n",
    "    codes = tf.cast(predicted_codes[0], tf.int32)\n",
    "    \n",
    "    # Decode the index of caracter\n",
    "    text = decode_codes(codes, char_list)\n",
    "    \n",
    "    # Convert a SparseTensor to string\n",
    "    text = tf.sparse.to_dense(text).numpy().astype(str)\n",
    "    \n",
    "    return list(map(lambda x: ''.join(x), text))\n",
    "\n",
    "predicted_transcriptions = greedy_decoder(model(np.expand_dims(X_test[:10], -1)))\n",
    "list(zip(predicted_transcriptions, y_test[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d35786cd2f650d46a54538d5478b9f72cd10ae51458c3726c4e0b827258ea8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
