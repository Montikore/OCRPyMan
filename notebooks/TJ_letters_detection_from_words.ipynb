{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problématique\n",
    "\n",
    "<h3> Prédire le mot dans l'image </h3>\n",
    "\n",
    "- Sample de 1000 observations (1000 mots) : charger (function preprocess (utiliser en sortie un .numpy() pour avoir des arrays), container toutes observations pour faire une matrice de taille (nb_observation, nb_features).\n",
    "- Modèle Deep learning : RNN\n",
    "- Évaluation du modèle : ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from os.path import exists\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import letter_detection_utils as ld_util\n",
    "import preprocessing as pp\n",
    "import ressources as rss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ld_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Pour recharger les libs pendant les devs\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m reload \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m reload(ld_util)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reload(pp)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reload(rss)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ld_util' is not defined"
     ]
    }
   ],
   "source": [
    "# Pour recharger les libs pendant les devs\n",
    "from importlib import reload \n",
    "reload(ld_util)\n",
    "reload(pp)\n",
    "reload(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIDOUILLE SALE!! pour importer des fichiers qui ne sont pas dans le meme repertoire. les fichiers devront être mieux rangés par la suite\n",
    "# import sys\n",
    "# sys.path.insert(1, '../')\n",
    "\n",
    "# import preprocessing as pp\n",
    "# import ressources as rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables globales\n",
    "rss.init()\n",
    "\n",
    "# LONG! 20mn (utile pour reprendre tout le preprocessing)\n",
    "# word_df = pd.DataFrame(pp.parse_my_word_file(rss.WORDS_META_FILENAME), columns=rss.WORD_COLUMNS)\n",
    "# word_df = pp.prepro_word(word_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Filtering data: taking only letters\n",
      "Using 50002 rows\n",
      "Starting preprocessing of images with tensorflow\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 8\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m img_size \u001b[39m=\u001b[39m (\u001b[39m32\u001b[39m, \u001b[39m128\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# data = ld_util.get_dataframe_with_preprocessed_imgs(\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#     img_size=img_size,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#     pickle_name=\"test\",\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#     with_edge_detection = False\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data_edge_50k \u001b[39m=\u001b[39m ld_util\u001b[39m.\u001b[39;49mget_dataframe_with_preprocessed_imgs(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     nb_rows \u001b[39m=\u001b[39;49m \u001b[39m50002\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     img_size\u001b[39m=\u001b[39;49mimg_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     load_pickle_if_exists \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     pickle_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest_edge_50k\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     with_edge_detection \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# df = data['df']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# preprocessed_imgs = data['preprocessed_imgs']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df_edge \u001b[39m=\u001b[39m data_edge_50k[\u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\letter_detection_utils.py:121\u001b[0m, in \u001b[0;36mget_dataframe_with_preprocessed_imgs\u001b[1;34m(nb_rows, img_size, load_pickle_if_exists, debug, pickle_name, with_edge_detection)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m debug: \n\u001b[0;32m    119\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting preprocessing of images with tensorflow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m preprocessed_imgs \u001b[39m=\u001b[39m process_df_img(df, img_size, with_edge_detection\u001b[39m=\u001b[39;49mwith_edge_detection)\n\u001b[0;32m    122\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m    123\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m: df,\n\u001b[0;32m    124\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpreprocessed_imgs\u001b[39m\u001b[39m'\u001b[39m: preprocessed_imgs\n\u001b[0;32m    125\u001b[0m }\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m debug: \n",
      "File \u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\letter_detection_utils.py:183\u001b[0m, in \u001b[0;36mprocess_df_img\u001b[1;34m(df, img_size, with_edge_detection)\u001b[0m\n\u001b[0;32m    180\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/temp/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m file_name \n\u001b[0;32m    182\u001b[0m     cv2\u001b[39m.\u001b[39mimwrite(path, edged)\n\u001b[1;32m--> 183\u001b[0m     cv2\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m    184\u001b[0m     \u001b[39m# contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m new_row \u001b[39m=\u001b[39m preprocess(path, img_size\u001b[39m=\u001b[39mimg_size,  data_augmentation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, is_threshold\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "img_size = (32, 128)\n",
    "# data = ld_util.get_dataframe_with_preprocessed_imgs(\n",
    "#     img_size=img_size,\n",
    "#     pickle_name=\"test\",\n",
    "#     with_edge_detection = False\n",
    "# )\n",
    "data_edge_50k = ld_util.get_dataframe_with_preprocessed_imgs(\n",
    "    nb_rows = 50002,\n",
    "    img_size=img_size,\n",
    "    load_pickle_if_exists = False,\n",
    "    pickle_name=\"test_edge_50k\",\n",
    "    with_edge_detection = True\n",
    ")\n",
    "\n",
    "# df = data['df']\n",
    "# preprocessed_imgs = data['preprocessed_imgs']\n",
    "\n",
    "df_edge = data_edge_50k['df']\n",
    "preprocessed_imgs_edge = data_edge_50k['preprocessed_imgs']\n",
    "\n",
    "# print(\"Length: \", len(df))\n",
    "# print(\"Imgs length: \", len(preprocessed_imgs))\n",
    "# print(\"Img shape: \", preprocessed_imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>michelson_contrast</th>\n",
       "      <th>gray_level_mot</th>\n",
       "      <th>word_id</th>\n",
       "      <th>gray_level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>transcription</th>\n",
       "      <th>word_img_path</th>\n",
       "      <th>form_img_path</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.850391</td>\n",
       "      <td>a01-003u-02-00</td>\n",
       "      <td>161</td>\n",
       "      <td>356</td>\n",
       "      <td>1174</td>\n",
       "      <td>181</td>\n",
       "      <td>78</td>\n",
       "      <td>M Ps</td>\n",
       "      <td>../data/words/a01/a01-003u/a01-003u-02-00.png</td>\n",
       "      <td>../data/formsA-D/a01-003u.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>890</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.888386</td>\n",
       "      <td>a01-020-08-00</td>\n",
       "      <td>176</td>\n",
       "      <td>355</td>\n",
       "      <td>2360</td>\n",
       "      <td>338</td>\n",
       "      <td>73</td>\n",
       "      <td>proposed</td>\n",
       "      <td>../data/words/a01/a01-020/a01-020-08-00.png</td>\n",
       "      <td>../data/formsA-D/a01-020.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.890996</td>\n",
       "      <td>a01-000x-05-00</td>\n",
       "      <td>173</td>\n",
       "      <td>393</td>\n",
       "      <td>1635</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>0M P</td>\n",
       "      <td>../data/words/a01/a01-000x/a01-000x-05-00.png</td>\n",
       "      <td>../data/formsA-D/a01-000x.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273</td>\n",
       "      <td>0.777003</td>\n",
       "      <td>0.814142</td>\n",
       "      <td>a01-003x-07-04</td>\n",
       "      <td>168</td>\n",
       "      <td>1310</td>\n",
       "      <td>2126</td>\n",
       "      <td>123</td>\n",
       "      <td>94</td>\n",
       "      <td>take</td>\n",
       "      <td>../data/words/a01/a01-003x/a01-003x-07-04.png</td>\n",
       "      <td>../data/formsA-D/a01-003x.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>957</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.602413</td>\n",
       "      <td>a01-020u-08-05</td>\n",
       "      <td>167</td>\n",
       "      <td>1667</td>\n",
       "      <td>2219</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>a</td>\n",
       "      <td>../data/words/a01/a01-020u/a01-020u-08-05.png</td>\n",
       "      <td>../data/formsA-D/a01-020u.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  michelson_contrast  gray_level_mot         word_id  gray_level  \\\n",
       "0    172            0.783217        0.850391  a01-003u-02-00         161   \n",
       "1    890            0.764706        0.888386   a01-020-08-00         176   \n",
       "2     83            0.683168        0.890996  a01-000x-05-00         173   \n",
       "3    273            0.777003        0.814142  a01-003x-07-04         168   \n",
       "4    957            0.818841        0.602413  a01-020u-08-05         167   \n",
       "\n",
       "      x     y    w   h transcription  \\\n",
       "0   356  1174  181  78          M Ps   \n",
       "1   355  2360  338  73      proposed   \n",
       "2   393  1635  190  85          0M P   \n",
       "3  1310  2126  123  94          take   \n",
       "4  1667  2219   45  26             a   \n",
       "\n",
       "                                   word_img_path  \\\n",
       "0  ../data/words/a01/a01-003u/a01-003u-02-00.png   \n",
       "1    ../data/words/a01/a01-020/a01-020-08-00.png   \n",
       "2  ../data/words/a01/a01-000x/a01-000x-05-00.png   \n",
       "3  ../data/words/a01/a01-003x/a01-003x-07-04.png   \n",
       "4  ../data/words/a01/a01-020u/a01-020u-08-05.png   \n",
       "\n",
       "                   form_img_path  length  \n",
       "0  ../data/formsA-D/a01-003u.png       4  \n",
       "1   ../data/formsA-D/a01-020.png       8  \n",
       "2  ../data/formsA-D/a01-000x.png       4  \n",
       "3  ../data/formsA-D/a01-003x.png       4  \n",
       "4  ../data/formsA-D/a01-020u.png       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(df_edge))\n",
    "# print(len(preprocessed_imgs_edge))\n",
    "# print(len(df))\n",
    "# print(len(preprocessed_imgs))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_imgs_edge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 10\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#CELLULE UNIQUEMENT LA POUR JOUER/VERIFIER LES DONNES\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#     plt.title(df.iloc[i].transcription + ' ' + str(df.iloc[i].length))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#     j+=1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m j \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m random_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(low\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, high\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(preprocessed_imgs_edge), size\u001b[39m=\u001b[39m[\u001b[39m10\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m14\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m random_indexes:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_imgs_edge' is not defined"
     ]
    }
   ],
   "source": [
    "#CELLULE UNIQUEMENT LA POUR JOUER/VERIFIER LES DONNES\n",
    "\n",
    "\n",
    "# j = 1\n",
    "# random_indexes = np.random.randint(low=0, high=len(preprocessed_imgs), size=[10])\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# for i in random_indexes:\n",
    "#     plt.subplot(2, 5, j)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(preprocessed_imgs[i].reshape(img_size), cmap='gray');\n",
    "#     plt.title(df.iloc[i].transcription + ' ' + str(df.iloc[i].length))\n",
    "#     j+=1\n",
    "    \n",
    "j = 1\n",
    "random_indexes = np.random.randint(low=0, high=len(preprocessed_imgs_edge), size=[10])\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in random_indexes:\n",
    "    plt.subplot(2, 5, j)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(preprocessed_imgs_edge[i].reshape(img_size), cmap='gray');\n",
    "    plt.title(df_edge.iloc[i].transcription + ' ' + str(df_edge.iloc[i].length) + '(size : ' + str(len(preprocessed_imgs_edge[i])) + ')')\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le rapport, expliquer le choix des algos (RNN, CTC) par le fait qu'on ne connait pas l'alignement des lettres dans les mots, mais qu'elles suivent une certaine logique dans le temps (le nombre de mot étant fini, les lettres ont des probas plus ou moins fortes de suivre une autre lettre). Ces algos sont capables de traiter ce cas là."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\".join([txt for txt in df_edge['transcription']])\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(set(corpus))}\n",
    "\n",
    "# pour encoder :\n",
    "# text_as_int = [char2idx[c] for c in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'j': 0, 'B': 1, '-': 2, 'v': 3, 'r': 4, 'l': 5, 'h': 6, 'G': 7, 'K': 8, 't': 9, 'C': 10, 'm': 11, 'o': 12, 'P': 13, 'E': 14, 'u': 15, 'a': 16, 'e': 17, 'f': 18, 'k': 19, 'g': 20, '0': 21, 'Y': 22, 'H': 23, 'W': 24, 'y': 25, 'w': 26, 'I': 27, 'n': 28, 'x': 29, 'd': 30, 'L': 31, \"'\": 32, 'J': 33, 'U': 34, 'F': 35, 'i': 36, 'A': 37, 'D': 38, 'O': 39, 'N': 40, '.': 41, 'S': 42, 'q': 43, 'M': 44, 'V': 45, 'c': 46, ' ': 47, 's': 48, 'R': 49, 'p': 50, 'b': 51, 'T': 52}\n"
     ]
    }
   ],
   "source": [
    "print(char2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case characters = 25 Upper case characters = 23\n"
     ]
    }
   ],
   "source": [
    "# ATTENTION TOUTES LES LETTRES NE SONT PAS REPRESENTEES AVEC UN ECHANTILLON DE 1000 mots!\n",
    "ld_util.upper_lower(''.join(char2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessed_imgs_edge\n",
    "\n",
    "# y pre-transformée en index de caracteres pour avoir des valeurs numériques\n",
    "# y = list()\n",
    "# tmp = list()\n",
    "# for word in df_edge['transcription']:\n",
    "#     for letter in word:\n",
    "#         tmp.append(char2idx[letter])\n",
    "#     y.append(tmp)\n",
    "#     tmp = list()\n",
    "\n",
    "# print(y[:5])\n",
    "\n",
    "# y sans transofrmation\n",
    "y = df_edge['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 128, 32, 32)       832       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128, 32, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 128, 32, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 64, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 16, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 32, 8, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 32, 8, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 32, 8, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 32, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 4, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 4, 128)        147584    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 32, 4, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 32, 4, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 32, 2, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 2, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32, 2, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 32, 2, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 1, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 32, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32, 512)          789504    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32, 100)           51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,411,940\n",
      "Trainable params: 1,410,724\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "############\n",
    "# Layer 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='SAME', input_shape = (128, 32, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), padding='SAME'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2)))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='SAME'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2)))\n",
    "\n",
    "# Layer 5\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='SAME'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(1,2), strides=(1,2)))\n",
    "#####################\n",
    "\n",
    "\n",
    "# Remove axis 2\n",
    "model.add(Lambda(lambda x :tf.squeeze(x, axis=2)))\n",
    "numHidden = 256\n",
    "# Bidirectionnal RNN\n",
    "model.add(Bidirectional(GRU(numHidden, return_sequences=True)))\n",
    "model.add(Dense(100))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22b28f92670>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.swapaxes(X, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape(-1, 128, 32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=126)\n",
    "\n",
    "#Definition du dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(X_train,-1), y_train))\n",
    "dataset = dataset.shuffle(1000).batch(64)\n",
    "\n",
    "########################## imports\n",
    "import sys\n",
    "import string\n",
    "import time\n",
    "############################## vars\n",
    "\n",
    "charList = list(string.ascii_letters)+[' ']\n",
    "# Définition d'un optimisateur Adam\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "################# functions\n",
    "def loss(labels, logits):\n",
    "    return tf.reduce_mean(\n",
    "            tf.nn.ctc_loss(\n",
    "                labels = labels,\n",
    "                logits = logits,\n",
    "                logit_length = [logits.shape[1]]*logits.shape[0],\n",
    "                label_length = None,\n",
    "                logits_time_major = False,\n",
    "                blank_index=-1\n",
    "            )\n",
    "        )\n",
    "\n",
    "def train_op(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Prédiction de notre modèle\n",
    "        y_pred = model(inputs, training=True)\n",
    "        # Calcule de l'erreur de notre modèle\n",
    "        loss_value = tf.reduce_mean(loss(targets, y_pred))\n",
    "       \n",
    "    # Calculer le gradient de la fonction de perte\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    # Descente de gradient\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Retourner la valeur de la fonction de perte\n",
    "    return loss_value.numpy()\n",
    "\n",
    "def encode_labels(labels, charList):\n",
    "    # Hash Table\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            charList,\n",
    "            np.arange(len(charList)),\n",
    "            value_dtype=tf.int32\n",
    "        ),\n",
    "        -1,  ### !!!!! pourquoi -1? ça echoue dans la ctc loss a cause de labels négatifs...  !!!!!!!!!!!!!!!!!!!! ????????????\n",
    "        name='char2id'\n",
    "    )\n",
    "    return table.lookup(\n",
    "    tf.compat.v1.string_split(labels, delimiter=''))\n",
    "    \n",
    "def decode_codes(codes, charList):\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(\n",
    "            np.arange(len(charList)),\n",
    "            charList,\n",
    "            key_dtype=tf.int32\n",
    "        ),\n",
    "        '',\n",
    "        name='id2char'\n",
    "    )\n",
    "    return table.lookup(codes)\n",
    "\n",
    "def greedy_decoder(logits):\n",
    "    # ctc beam search decoder\n",
    "    predicted_codes, _ = tf.nn.ctc_greedy_decoder(\n",
    "        # shape of tensor [max_time x batch_size x num_classes] \n",
    "        tf.transpose(logits, (1, 0, 2)),\n",
    "        [logits.shape[1]]*logits.shape[0]\n",
    "    )\n",
    "    \n",
    "    # convert to int32\n",
    "    codes = tf.cast(predicted_codes[0], tf.int32)\n",
    "    \n",
    "    # Decode the index of caracter\n",
    "    text = decode_codes(codes, charList)\n",
    "    \n",
    "    # Convert a SparseTensor to string\n",
    "    text = tf.sparse.to_dense(text).numpy().astype(str)\n",
    "    \n",
    "    return list(map(lambda x: ''.join(x), text))\n",
    "\n",
    "#####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387       face\n",
      "890        his\n",
      "107       Said\n",
      "125        Sir\n",
      "835    despite\n",
      "Name: transcription, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 7), dtype=string, numpy=\n",
       "array([[b'f', b'a', b'c', b'e', b'', b'', b''],\n",
       "       [b'h', b'i', b's', b'', b'', b'', b''],\n",
       "       [b'S', b'a', b'i', b'd', b'', b'', b''],\n",
       "       [b'S', b'i', b'r', b'', b'', b'', b''],\n",
       "       [b'd', b'e', b's', b'p', b'i', b't', b'e']], dtype=object)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = decode_codes(encode_labels(y_train[0:5], charList), charList)\n",
    "print(y_train[0:5])\n",
    "tf.sparse.to_dense(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "15.074645\n",
      "15.545877\n",
      "16.511051\n",
      "15.724434\n",
      "15.947632\n",
      "16.257952\n",
      "15.608845\n",
      "17.48657\n",
      "16.257915\n",
      "16.303701\n",
      "15.868623\n",
      "16.68809\n",
      "15.399214\n",
      "---- Epoch 1 ----\n",
      "17.90725\n",
      "16.191425\n",
      "15.232109\n",
      "15.279183\n",
      "15.914436\n",
      "16.492435\n",
      "17.077843\n",
      "17.123234\n",
      "13.369043\n",
      "14.201501\n",
      "17.115183\n",
      "15.258505\n",
      "16.519527\n",
      "---- Epoch 2 ----\n",
      "13.863358\n",
      "17.25161\n",
      "14.616725\n",
      "16.622005\n",
      "16.567463\n",
      "16.465319\n",
      "14.361706\n",
      "15.492306\n",
      "15.443266\n",
      "16.3494\n",
      "15.660645\n",
      "17.245363\n",
      "14.5485935\n",
      "---- Epoch 3 ----\n",
      "15.170677\n",
      "15.618124\n",
      "14.940733\n",
      "15.426996\n",
      "15.114734\n",
      "15.027175\n",
      "15.665073\n",
      "15.028481\n",
      "16.571095\n",
      "16.168385\n",
      "16.651482\n",
      "15.957669\n",
      "16.210205\n",
      "---- Epoch 4 ----\n",
      "14.406399\n",
      "15.847306\n",
      "16.127457\n",
      "16.132326\n",
      "15.898359\n",
      "16.143118\n",
      "15.376791\n",
      "14.170116\n",
      "16.163425\n",
      "15.21678\n",
      "15.264494\n",
      "15.225193\n",
      "15.799257\n",
      "---- Epoch 5 ----\n",
      "13.560513\n",
      "17.601894\n",
      "15.587606\n",
      "15.410868\n",
      "15.961496\n",
      "15.25642\n",
      "13.74343\n",
      "14.329175\n",
      "15.408746\n",
      "15.621776\n",
      "15.2096\n",
      "17.052822\n",
      "15.303622\n",
      "---- Epoch 6 ----\n",
      "14.802531\n",
      "16.104977\n",
      "16.128794\n",
      "16.294704\n",
      "14.269992\n",
      "15.39913\n",
      "16.949026\n",
      "16.145327\n",
      "16.128922\n",
      "13.570578\n",
      "13.823458\n",
      "14.50586\n",
      "13.432592\n",
      "---- Epoch 7 ----\n",
      "14.455158\n",
      "15.243395\n",
      "16.37211\n",
      "14.704932\n",
      "14.255431\n",
      "14.876526\n",
      "13.6696205\n",
      "15.609831\n",
      "15.706624\n",
      "16.46318\n",
      "15.924238\n",
      "15.527614\n",
      "13.182155\n",
      "---- Epoch 8 ----\n",
      "16.854214\n",
      "14.244572\n",
      "13.507017\n",
      "15.2529335\n",
      "15.218597\n",
      "14.404741\n",
      "13.679501\n",
      "16.169012\n",
      "15.647921\n",
      "15.366764\n",
      "13.645593\n",
      "15.956818\n",
      "15.433891\n",
      "---- Epoch 9 ----\n",
      "17.22824\n",
      "16.058643\n",
      "14.351204\n",
      "14.098246\n",
      "15.081095\n",
      "14.02043\n",
      "13.370497\n",
      "15.738607\n",
      "13.795825\n",
      "16.367645\n",
      "14.439541\n",
      "14.335276\n",
      "14.015139\n",
      "---- Epoch 10 ----\n",
      "13.599947\n",
      "14.96774\n",
      "14.287934\n",
      "16.09011\n",
      "15.045732\n",
      "14.877874\n",
      "15.15769\n",
      "14.294675\n",
      "15.18194\n",
      "14.680277\n",
      "14.780423\n",
      "15.1782675\n",
      "12.3562765\n",
      "---- Epoch 11 ----\n",
      "15.475308\n",
      "15.506066\n",
      "13.968437\n",
      "14.309927\n",
      "12.8171835\n",
      "14.050808\n",
      "15.333581\n",
      "14.783728\n",
      "14.329748\n",
      "15.426744\n",
      "14.682245\n",
      "15.08133\n",
      "13.082245\n",
      "---- Epoch 12 ----\n",
      "15.163344\n",
      "14.694063\n",
      "13.397276\n",
      "13.687497\n",
      "16.130842\n",
      "13.6138935\n",
      "15.796858\n",
      "14.950298\n",
      "14.534821\n",
      "15.849266\n",
      "13.536711\n",
      "13.194703\n",
      "12.733696\n",
      "---- Epoch 13 ----\n",
      "14.343188\n",
      "15.083387\n",
      "14.60493\n",
      "14.555061\n",
      "13.342615\n",
      "14.977943\n",
      "15.154631\n",
      "13.858486\n",
      "14.080092\n",
      "14.234837\n",
      "13.905474\n",
      "14.02807\n",
      "14.886977\n",
      "---- Epoch 14 ----\n",
      "15.375421\n",
      "12.837895\n",
      "15.399138\n",
      "14.171455\n",
      "13.591534\n",
      "14.560364\n",
      "14.956276\n",
      "12.912762\n",
      "13.19318\n",
      "15.249742\n",
      "13.8641\n",
      "13.54747\n",
      "16.170746\n",
      "---- Epoch 15 ----\n",
      "14.785343\n",
      "14.111036\n",
      "13.332549\n",
      "13.621377\n",
      "13.230151\n",
      "14.001818\n",
      "14.61464\n",
      "15.19865\n",
      "13.638855\n",
      "13.69682\n",
      "14.5816765\n",
      "14.006441\n",
      "14.403775\n",
      "---- Epoch 16 ----\n",
      "14.724768\n",
      "13.281372\n",
      "12.045551\n",
      "13.832586\n",
      "14.499323\n",
      "12.443434\n",
      "13.563227\n",
      "15.356394\n",
      "15.266016\n",
      "13.118507\n",
      "15.639271\n",
      "12.9740925\n",
      "15.458445\n",
      "---- Epoch 17 ----\n",
      "13.251541\n",
      "13.082111\n",
      "12.505819\n",
      "13.710079\n",
      "15.437816\n",
      "12.136383\n",
      "15.110223\n",
      "13.986984\n",
      "13.131916\n",
      "14.385506\n",
      "14.928193\n",
      "14.573565\n",
      "12.979313\n",
      "---- Epoch 18 ----\n",
      "13.904579\n",
      "12.012037\n",
      "15.451927\n",
      "13.428259\n",
      "12.523285\n",
      "13.928371\n",
      "13.225834\n",
      "14.004639\n",
      "14.280748\n",
      "13.672783\n",
      "14.563213\n",
      "13.539835\n",
      "11.70578\n",
      "---- Epoch 19 ----\n",
      "13.646688\n",
      "13.62922\n",
      "14.254385\n",
      "13.662584\n",
      "12.245244\n",
      "13.511536\n",
      "14.275773\n",
      "12.570766\n",
      "14.263139\n",
      "12.987984\n",
      "13.231315\n",
      "12.8682785\n",
      "15.044874\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = 5\n",
    "# Entraînenement du modèle\n",
    "for i in range(epochs): \n",
    "    # Pour chaque epoch\n",
    "    print('---- Epoch', i, '----')\n",
    "    for X_b, y_b in dataset:\n",
    "        # try :\n",
    "        \n",
    "            y_ba = encode_labels(y_b, charList)\n",
    "            print(train_op(model, X_b, y_ba))\n",
    "        # except :\n",
    "        #     print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        #     time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'nominees'),\n",
       " ('', 'into'),\n",
       " ('', 'take'),\n",
       " ('', 'have'),\n",
       " ('', 'the'),\n",
       " ('', 'Mr.'),\n",
       " ('', 'support'),\n",
       " ('', 'last'),\n",
       " ('', 'talks'),\n",
       " ('', 'have'),\n",
       " ('', 'Parties'),\n",
       " ('', 'of'),\n",
       " ('', 'The'),\n",
       " ('', 'with'),\n",
       " ('', 'peers'),\n",
       " ('', 'Mr.'),\n",
       " ('', 'the'),\n",
       " ('', 'steps'),\n",
       " ('', 'Africans'),\n",
       " ('', 'of'),\n",
       " ('', 'forward'),\n",
       " ('', 'Government'),\n",
       " ('', 'overall'),\n",
       " ('', 'the'),\n",
       " ('', 'created'),\n",
       " ('', 'seeking'),\n",
       " ('', 'resolution'),\n",
       " ('', 'He'),\n",
       " ('', 'the'),\n",
       " ('', 'now')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = greedy_decoder(model(np.expand_dims(X_train[:30], -1)))\n",
    "list(zip(l, y_test[:30]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 5s 197ms/step\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "######TESTSSSSS\n",
    "\n",
    "# l = greedy_decoder(preds)\n",
    "# list(zip(l, y_test[:30]))\n",
    "from keras import backend as K\n",
    "\n",
    "preds = model.predict(X_train)\n",
    "\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "print(decoded[0])\n",
    "print(decoded[1])\n",
    "print(decoded[2])\n",
    "print(decoded[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Lancaster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 29\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_size):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     train_label_len[i] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_y[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X40sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     train_y_tmp[i, \u001b[39m0\u001b[39m:\u001b[39mlen\u001b[39m(train_y[i])]\u001b[39m=\u001b[39m train_y[i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X40sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m train_y \u001b[39m=\u001b[39m train_y_tmp\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X40sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m valid_y_tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones([valid_size, max_str_len]) \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Lancaster'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2, random_state=126)\n",
    "\n",
    "train_size = 800\n",
    "valid_size= 200\n",
    "\n",
    "train_x = np.array(train_x).reshape(-1, 128, 32, 1)\n",
    "valid_x = np.array(valid_x).reshape(-1, 128, 32, 1)\n",
    "\n",
    "\n",
    "alphabets = ''.join(char2idx)\n",
    "max_str_len = 30 # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
    "num_of_timestamps = 32 # max length of predicted labels   !!!!????? pourquoi diff de max_str_len ????\n",
    "\n",
    "\n",
    "# réarrangement des targets\n",
    "train_y_tmp = np.ones([train_size, max_str_len]) * -1\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
    "train_output = np.zeros([train_size])\n",
    "\n",
    "for i in range(train_size):\n",
    "    train_label_len[i] = len(train_y[i])\n",
    "    train_y_tmp[i, 0:len(train_y[i])]= train_y[i]\n",
    "\n",
    "train_y = train_y_tmp\n",
    "\n",
    "valid_y_tmp = np.ones([valid_size, max_str_len]) * -1\n",
    "valid_label_len = np.zeros([valid_size, 1])\n",
    "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
    "valid_output = np.zeros([valid_size])\n",
    "\n",
    "for i in range(valid_size):\n",
    "    valid_label_len[i] = len(valid_y[i])\n",
    "    valid_y_tmp[i, 0:len(valid_y[i])]= valid_y[i]\n",
    "\n",
    "valid_y = valid_y_tmp\n",
    "###############################\n",
    "train_y = train_y.astype('int')\n",
    "valid_y = valid_y.astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label :  is \n",
      "train_y :  [ 5 37 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] \n",
      "train_label_len :  [2.] \n",
      "train_input_len :  [30.]\n"
     ]
    }
   ],
   "source": [
    "print('True label : ',num_to_label(train_y[150]) , '\\ntrain_y : ',train_y[150],'\\ntrain_label_len : ',train_label_len[150], \n",
    "      '\\ntrain_input_len : ', train_input_len[150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 128, 32, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 128, 32, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128, 32, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128, 32, 32)       0         \n",
      "                                                                 \n",
      " max1 (MaxPooling2D)         (None, 64, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 64, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " max2 (MaxPooling2D)         (None, 32, 8, 64)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 8, 64)         0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 32, 8, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 32, 8, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32, 8, 128)        0         \n",
      "                                                                 \n",
      " max3 (MaxPooling2D)         (None, 32, 4, 128)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 4, 128)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 32, 512)           0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32, 32)            16416     \n",
      "                                                                 \n",
      " lstm1 (Bidirectional)       (None, 32, 256)           164864    \n",
      "                                                                 \n",
      " lstm2 (Bidirectional)       (None, 32, 256)           394240    \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32, 54)            13878     \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 32, 54)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 682,966\n",
      "Trainable params: 682,518\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(128, 32, 1), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((32, 512)), name='reshape')(inner)\n",
    "inner = Dense(32, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(128, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(128, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TiBo\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 21s 1s/step - loss: 94.5986 - val_loss: 84.5896\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 7s 1s/step - loss: 68.6965 - val_loss: 55.1174\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 8s 1s/step - loss: 39.5660 - val_loss: 30.6476\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 11s 1s/step - loss: 23.4687 - val_loss: 21.3218\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 20.3729 - val_loss: 19.8857\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 8s 1s/step - loss: 20.4571 - val_loss: 19.6912\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 8s 1s/step - loss: 20.0495 - val_loss: 19.3077\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 8s 1s/step - loss: 19.3105 - val_loss: 18.9593\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 8s 1s/step - loss: 18.8396 - val_loss: 18.7843\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 10s 1s/step - loss: 18.6092 - val_loss: 18.6348\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 18.3559 - val_loss: 18.4223\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 18.1268 - val_loss: 18.2096\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.9465 - val_loss: 18.0549\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.7865 - val_loss: 17.9390\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.6636 - val_loss: 17.8378\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.5558 - val_loss: 17.7457\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.4689 - val_loss: 17.6618\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.4013 - val_loss: 17.5990\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.3450 - val_loss: 17.5558\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 10s 1s/step - loss: 17.2913 - val_loss: 17.5115\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.2328 - val_loss: 17.4359\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.1917 - val_loss: 17.3801\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.1469 - val_loss: 17.3574\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.1132 - val_loss: 17.3180\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.0740 - val_loss: 17.2568\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.0432 - val_loss: 17.2240\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 17.0064 - val_loss: 17.2082\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 16.9808 - val_loss: 17.1781\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 16.9416 - val_loss: 17.1488\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 9s 1s/step - loss: 16.9235 - val_loss: 17.0962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221e18e64f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n",
    "\n",
    "model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n",
    "                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n",
    "                epochs=30, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 108ms/step\n",
      "True :  [41 47  0 44  8 45 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [47  5 36 51 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [38 33 51 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [44  8 38 18 36 47 38 51 36 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [41 47  0 44  8 45 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [35 44  8 37 51 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [29 51 51 45 51 37 37 51 37 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [44 11 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [ 1  5 38 33 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [52 45 39 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [47  5 36 51 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [38 33 51 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [ 1 47  7 38 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [33 47 37 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n",
      "True :  [ 7  8 21  0 51 45 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1] !! Pred :  \n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(valid_x)\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "prediction = []\n",
    "for i in range(valid_size):\n",
    "    prediction.append(num_to_label(decoded[i]))\n",
    "\n",
    "\n",
    "for i in range(15):\n",
    "    print('True : ', valid_y[i], '!! Pred : ', prediction[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604688\n",
      "0.16396892\n",
      "[4.9847453e-03 2.9768948e-03 8.1923458e-04 8.9015142e-04 7.6956960e-04\n",
      " 2.0462085e-02 1.2863055e-03 1.6341049e-02 6.0865306e-03 1.1699783e-03\n",
      " 5.6109915e-04 4.7165891e-03 2.7098267e-03 5.7641394e-04 7.9892110e-03\n",
      " 7.8785542e-04 9.1743318e-04 1.0907425e-03 1.4652216e-03 4.1377041e-03\n",
      " 4.7452201e-04 5.6902366e-03 9.0594823e-04 1.0149240e-03 2.8216569e-03\n",
      " 4.5166168e-04 1.2793371e-03 9.0223858e-03 1.0829429e-03 1.6396625e-03\n",
      " 6.3770817e-04 5.7237246e-04 2.9050608e-03 9.3423249e-03 8.1382145e-04\n",
      " 8.9002581e-04 8.3906660e-03 1.4308949e-02 1.9362848e-02 1.1634919e-03\n",
      " 1.2392041e-03 2.5124033e-03 1.1767129e-03 7.6047838e-04 2.6156796e-02\n",
      " 1.6275078e-02 1.8271438e-03 1.7413078e-02 1.0891625e-03 3.2412636e-04\n",
      " 2.1784434e-03 3.8823113e-02 2.1765663e-03 7.2453851e-01]\n",
      "53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 \n",
      " [44  8 38 18 36 47 38 51 36 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 31\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39margmax(preds[\u001b[39m3\u001b[39m][i]), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, valid_y[\u001b[39m3\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(num_to_label([np\u001b[39m.\u001b[39;49margmax(preds[\u001b[39m3\u001b[39;49m][\u001b[39m0\u001b[39;49m])]))\n",
      "\u001b[1;32md:\\GitHub\\OCRpyMAN\\notebooks\\TJ_letters_detection_from_words.ipynb Cellule 31\u001b[0m in \u001b[0;36mnum_to_label\u001b[1;34m(num)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         ret\u001b[39m+\u001b[39m\u001b[39m=\u001b[39malphabets[ch]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/OCRpyMAN/notebooks/TJ_letters_detection_from_words.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "print(max([item for sublist in preds[3] for item in sublist]))\n",
    "print(max([item for item in preds[3][0]]))\n",
    "# print(decoded[:5])\n",
    "print(preds[3][10])\n",
    "for i in range(len(preds[3])):\n",
    "    print(np.argmax(preds[3][i]), end=' ')\n",
    "print('\\n', valid_y[3])\n",
    "\n",
    "print(num_to_label([np.argmax(preds[3][0])]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "646607af5cee56728deff5007f5747c6b792545c0f7c2f22c37576bfe12603f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
